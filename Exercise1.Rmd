---
title: "Excercise1"
author: "Xiaohan Sun / Liyuan Zhang / Evelyn Cheng"
date: "2021/2/6"
output: word_document
---
# ECO 395M Homework 1: Xiaohan Sun / Liyuan Zhang / Evelyn Cheng 

## 1) Data visualization: gas prices

(A)

```{r}
library(tidyverse)
library(ggplot2)
GasPrices = read.csv('../data/GasPrices.csv')
head(GasPrices)
ggplot(data=GasPrices) + 
  geom_boxplot(aes(x=Price, y=Competitors))
```

**Claim:** Gas stations charge more if they lack direct competition in sight.

**Conclusion:** As the graph shows, the median price for gas stations that lacking competitors is higher than the one having competitors. Also, upper edge and upper quartile price are higher than the one having competitors. So, this claim is correct.

(B)

```{r}
summary(GasPrices$Income)
ggplot(data=GasPrices) + 
  geom_point(aes(x=Price, y=Income))+
  ylim(12780,128560)
```
  
**Claim:** The richer the area, the higher the gas price.

**Conclusion:** As shown in the figure, when the income is higher, the dots will fall more on the right. The trend for this scatter plot is increasing. So, this claim is correct.

(C)

```{r}
GasPricesC = GasPrices %>%
  group_by(Brand) %>%
  summarise(meanprice=mean(Price))
ggplot(data=GasPricesC) + 
  geom_col(aes(x=meanprice, y=Brand)) + 
  scale_x_continuous(breaks=seq(0,2,0.2)) +
  geom_vline(xintercept=1.84,col="red")
```
  
**Claim:** Shell charges more than other brands.

**Conclusion:** In the bar chart, the bar of shell has higher price compared with Other brands. So, this claim is correct.

(D)

```{r}
ggplot(data=GasPrices,aes(x=Price,fill=Stoplight))+geom_histogram(bins = 30, alpha=0.4, position = "identity")
```

**Claim:** Gas stations at stoplights charge more.

**Conclusion:** The histogram present that the pick price for gas stations at stoplights (which is the blue one) is higher than the one doesn't (pink bars). So, this claim is correct.

(E)

```{r}
ggplot(data=GasPrices) + 
  geom_boxplot(aes(x=Price, y=Highway))
```


**Claim:** Gas stations with direct highway access charge more.

**Conclusion:** As the graph shows, the median price for gas stations  with direct highway access is higher than the one without. Also, upper quartile price are higher than the one without direct highway access. So, this claim is correct.

## 4) K-nearest neighbors

i. 350

```{r}
library(tidyverse)
library(ggplot2)
library(mosaic)
library(FNN)
library(foreach)
library(rsample)
library(caret)
library(modelr)
library(parallel)

sclass = read.csv('../data/sclass.csv')

sclass350 = subset(sclass, trim == '350')

# Split the data into a training and a testing set
sclass350_split = initial_split(sclass350, prop=0.9)
sclass350_train = training(sclass350_split)
sclass350_test  = testing(sclass350_split)

# RMSE for each value of K
N = nrow(sclass350)
N_train = floor(0.8*N)
k_grid = unique(round(exp(seq(log(N_train), log(2), length=100))))

rmse_out = foreach(k = k_grid, .combine='rbind') %dopar% {
  this_rmse = foreach(k = k_grid, .combine='c') %do% {
    knn_model = knnreg(price ~ mileage, data=sclass350_train, k = k, use.all=TRUE)
    modelr::rmse(knn_model, sclass350_test)
  }
  data.frame(k=k_grid, rmse=this_rmse)
}
rmse_out = arrange(rmse_out, k)
ggplot(rmse_out) + 
  geom_boxplot(aes(x=factor(k), y=rmse)) + 
  theme_bw(base_size=10) +
  scale_x_discrete(breaks=c(5,10,15,20,25,30,40,50,80,100)) +
  labs (titles = "RMSE for each value of K - 350")

#  K-nearest-neighbors
rmse_grid_out = foreach(k = k_grid, .combine='c') %do% {
  knn_model = knnreg(price ~ mileage, data=sclass350_train, k = k, use.all=TRUE)
  modelr::rmse(knn_model, sclass350_test)
}
rmse_grid_out = data.frame(K = k_grid, RMSE = rmse_grid_out)

p_out = ggplot(data=rmse_grid_out) + 
  theme_bw(base_size = 10) + 
  geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5)

ind_best = which.min(rmse_grid_out$RMSE)
k_best = k_grid[ind_best]

rmse_grid_in = foreach(k = k_grid, .combine='c') %do% {
  knn_model = knnreg(price ~ mileage, data=sclass350_train, k = k, use.all=TRUE)
  modelr::rmse(knn_model, sclass350_train)
}
rmse_grid_in = data.frame(K = k_grid, RMSE = rmse_grid_in)
p_out + geom_path(data=rmse_grid_in, aes(x=K, y=RMSE, color='trainset'),size=0.5) +
  scale_colour_manual(name="RMSE",
                      values=c(testset="black", trainset="grey")) + 
  geom_vline(xintercept=k_best, color='darkgreen', size=1) +
  labs (titles = "K-nearest neighbors: test - 350")

# fitted model
knn = knnreg(price ~ mileage, data=sclass350_train, k=k_best)
sclass350 = sclass350 %>%
  mutate(price_pre = predict(knn, sclass350))
g350 = ggplot(data = sclass350) + 
  geom_point(mapping = aes(x = mileage, y = price), color='darkgrey')
g350 + geom_line(aes(x = mileage, y = price_pre), color='red', size=1.5) +
  labs (titles = "fitted model - 350")

```

ii. 65 AMG

```{r}
# Split the data into a training and a testing set
sclass65AMG = subset(sclass, trim == '65 AMG')

sclass65AMG_split = initial_split(sclass65AMG, prop=0.9)
sclass65AMG_train = training(sclass65AMG_split)
sclass65AMG_test  = testing(sclass65AMG_split)

# RMSE for each value of K
N65AMG = nrow(sclass65AMG)
N_train65AMG = floor(0.8*N65AMG)
k_grid65AMG = unique(round(exp(seq(log(N_train65AMG), log(2), length=100))))
rmse_out65AMG = foreach(k = k_grid65AMG, .combine='rbind') %dopar% {
  this_rmse = foreach(k = k_grid65AMG, .combine='c') %do% {
    knn_model = knnreg(price ~ mileage, data=sclass65AMG_train, k = k, use.all=TRUE)
    modelr::rmse(knn_model, sclass65AMG_test)
  }
  data.frame(k=k_grid65AMG, rmse=this_rmse)
}
rmse_out65AMG = arrange(rmse_out65AMG, k)
ggplot(rmse_out65AMG) + 
  geom_boxplot(aes(x=factor(k), y=rmse)) + 
  theme_bw(base_size=8) +
  scale_x_discrete(breaks=c(5,10,15,20,25,30,40,50,80,100)) +
  labs (titles = "RMSE for each value of K - 65AMG")

#  K-nearest-neighbors
rmse_grid_out65AMG = foreach(k = k_grid65AMG, .combine='c') %do% {
  knn_model = knnreg(price ~ mileage, data=sclass65AMG_train, k = k, use.all=TRUE)
  modelr::rmse(knn_model, sclass65AMG_test)
}
rmse_grid_out65AMG = data.frame(K = k_grid65AMG, RMSE = rmse_grid_out65AMG)
p_out = ggplot(data=rmse_grid_out65AMG) + 
  theme_bw(base_size = 10) + 
  geom_path(aes(x=K, y=RMSE, color='testset'), size=0.5)

ind_best65AMG = which.min(rmse_grid_out65AMG$RMSE)
k_best65AMG = k_grid65AMG[ind_best65AMG]

rmse_grid_in2 = foreach(k = k_grid65AMG, .combine='c') %do% {
  knn_model = knnreg(price ~ mileage, data=sclass65AMG_train, k = k, use.all=TRUE)
  modelr::rmse(knn_model, sclass65AMG_train)
}
rmse_grid_in2 = data.frame(K = k_grid65AMG, RMSE = rmse_grid_in2)
p_out + geom_path(data=rmse_grid_in2, aes(x=K, y=RMSE, color='trainset'),size=0.5) +
  scale_colour_manual(name="RMSE",
                      values=c(testset="black", trainset="grey")) + 
  geom_vline(xintercept=k_best65AMG, color='darkgreen', size=1)+
  labs (titles = "K-nearest neighbors: test - 65 AMG")

# fitted model
knn65AMG = knnreg(price ~ mileage, data=sclass65AMG_train, k=k_best65AMG)
sclass65AMG = sclass65AMG %>%
  mutate(price_pre = predict(knn65AMG, sclass65AMG))
g65AMG = ggplot(data = sclass65AMG) + 
  geom_point(mapping = aes(x = mileage, y = price), color='darkgrey')
g65AMG + geom_line(aes(x = mileage, y = price_pre), color='red', size=1.5) +
  labs (titles = "fitted model - 65 AMG")

```

```{r}
k_best
k_best65AMG
dim(sclass350)
dim(sclass65AMG)
```

Trim 350 yields a larger optimal value of K. In the plot of RMSE versus K, trim 350 has the higher K. I reckon that it's due to trim 350 has more number of data than trim 65AMG. If the value of K is small, once there are noise components, they will have a greater impact on the prediction. When the value of K is large, it is equivalent to predicting with data in a larger neighborhood, and the approximate error of learning will increase. Because of dataset "sclass350" has more points , the optimal value of K can be larger in order to reduce the bias.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

